{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa2f862",
   "metadata": {},
   "source": [
    "# Playground Notebook\n",
    "\n",
    "This notebook is meant to be used to experiment with different parts of the code contained in the project regarding document parsing and extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DATABASE_URL'] = \"postgresql+psycopg2://postgres:postgres@localhost:5432/rfp_db\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d17c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "# Azure Imports\n",
    "from azure.storage.blob import BlobClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Local Imports from your existing codebase\n",
    "from config import config\n",
    "from shared.services.doc_intelligence import DocumentParser, MarginFilter\n",
    "\n",
    "# from shared.services.semantic import SemanticAnalyzer\n",
    "\n",
    "# from shared.services.semantic_5 import AgenticSemanticAnalyzer, extract_rfp_questions\n",
    "from shared.extractors import ExtractorFactory, QuestionExtractorConfig, QAExtractorConfig\n",
    "from shared.extractors.base import SectionType\n",
    "from shared.extractors import ExtractorFactory, QuestionExtractorConfig\n",
    "from shared.extractors.base import SectionType\n",
    "\n",
    "from shared.extractors.base.models import ExtractedQAPair\n",
    "\n",
    "from shared.extractors import ExtractorFactory\n",
    "import json\n",
    "import fitz\n",
    "import pymupdf4llm\n",
    "\n",
    "factory = ExtractorFactory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def get_blob_content(blob_url: str) -> bytes:\n",
    "    \"\"\"Downloads the blob content into memory.\"\"\"\n",
    "    logging.info(f\"Connecting to Blob: {blob_url.split('?')[0]}...\") # Log URL without SAS token\n",
    "    \n",
    "    try:\n",
    "        # Try connecting with Default Credential (env vars or az login)\n",
    "        # If the URL contains a SAS token, the credential is ignored automatically by the SDK\n",
    "        blob_client = BlobClient.from_blob_url(\n",
    "            blob_url, \n",
    "            credential=DefaultAzureCredential()\n",
    "        )\n",
    "        \n",
    "        download_stream = blob_client.download_blob()\n",
    "        return download_stream.readall()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to download blob: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "def analyze_pdf_with_docint(blob_url: str):\n",
    "    # Azure Blob Storage\n",
    "    pdf_bytes = get_blob_content(blob_url)\n",
    "    logging.info(f\"Downloaded {len(pdf_bytes)} bytes.\")\n",
    "\n",
    "    # Azure Document Intelligence\n",
    "    parser = DocumentParser()\n",
    "    logging.info(\"Sending to Azure Document Intelligence...\")\n",
    "    try:\n",
    "        # Parse stream expects a file-like object or bytes\n",
    "        result = parser.parse_stream(pdf_bytes)\n",
    "        \n",
    "        logging.info(\"Analysis Complete.\")\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Analysis failed: {e}\")\n",
    "\n",
    "\n",
    "def analyze_pdf_with_pymupdf4llm(blob_url: str):\n",
    "    # Azure Blob Storage\n",
    "    pdf_bytes = get_blob_content(blob_url)\n",
    "    logging.info(f\"Downloaded {len(pdf_bytes)} bytes.\")\n",
    "\n",
    "    # pymupdf4llm\n",
    "    doc = fitz.open(\"pdf\", pdf_bytes)\n",
    "    markdown_text = pymupdf4llm.to_markdown(doc)\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def analyze_pdf_free(pdf_filepath: str):\n",
    "    # Instead of Azure services, use pymupdf4llm to read\n",
    "    # a local PDF file\n",
    "    output = {}\n",
    "    doc = fitz.open(pdf_filepath)\n",
    "    pdf_bytes = doc.tobytes() \n",
    "    markdown_text = pymupdf4llm.to_markdown(doc)\n",
    "    output['content'] = markdown_text\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def levenshtein_distance(s1: str, s2: str) -> int:\n",
    "    \"\"\"Compute Levenshtein distance between two strings.\"\"\"\n",
    "    s1, s2 = s1.lower(), s2.lower()\n",
    "\n",
    "    if len(s1) < len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    previous_row = list(range(len(s2) + 1))\n",
    "\n",
    "    for i, c1 in enumerate(s1, start=1):\n",
    "        current_row = [i]\n",
    "        for j, c2 in enumerate(s2, start=1):\n",
    "            insertions = previous_row[j] + 1\n",
    "            deletions = current_row[j - 1] + 1\n",
    "            substitutions = previous_row[j - 1] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n",
    "\n",
    "\n",
    "def levenshtein_similarity(s1: str, s2: str) -> float:\n",
    "    \"\"\"\n",
    "    Normalize Levenshtein distance into a similarity score [0, 1].\n",
    "    1.0 = exact match\n",
    "    \"\"\"\n",
    "    distance = levenshtein_distance(s1, s2)\n",
    "    max_len = max(len(s1), len(s2))\n",
    "    return 1 - distance / max_len if max_len > 0 else 1.0\n",
    "\n",
    "\n",
    "def max_similarity_per_question(questions_dict, questions_ground_truth_2):\n",
    "    results = {}\n",
    "\n",
    "    for q_key, q_text in questions_dict.items():\n",
    "        best_match = None\n",
    "        best_score = 0.0\n",
    "\n",
    "        for gt_key, gt_text in questions_ground_truth_2.items():\n",
    "            score = levenshtein_similarity(q_text, gt_text)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = gt_key\n",
    "\n",
    "        results[q_key] = {\n",
    "            \"best_ground_truth_question\": best_match,\n",
    "            \"max_similarity\": round(best_score, 4)\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def count_accuracy(extracted_items, ground_truth_dict):\n",
    "    y_hat = len(extracted_items)\n",
    "    y = len(ground_truth_dict)\n",
    "    # acc = 1 - (abs(y_hat - y)/y)\n",
    "    acc = 1 - (y_hat - y)/y\n",
    "    return acc\n",
    "\n",
    "\n",
    "def content_similarity(extracted_items, ground_truth_items):\n",
    "    similarity_list = []\n",
    "    for y_hat in extracted_items:\n",
    "        similarity = max([levenshtein_similarity(y_hat, y) for y in ground_truth_items])\n",
    "        similarity_list.append(similarity)\n",
    "    return similarity_list\n",
    "\n",
    "\n",
    "def display_metrics(extractions, ground_truth, structure=None):\n",
    "\n",
    "    # Questions\n",
    "    y_questions = [q['question'] for q in ground_truth['questions_answers']]\n",
    "    yhat_questions = [q.question_text for q in extractions]\n",
    "    q_similarity = content_similarity(yhat_questions, y_questions)\n",
    "    print(f\"Question (or pair) count accuracy: {count_accuracy(yhat_questions, y_questions):.2f}\")\n",
    "    print(f\"Questions similarity: Average={np.mean(q_similarity):.2f} Min={np.min(q_similarity):.2f} Max={np.max(q_similarity):.2f}\")\n",
    "\n",
    "    # Answers\n",
    "    if type(extractions[0]) == ExtractedQAPair:\n",
    "        y_answers = [q['answer'] for q in ground_truth['questions_answers']]\n",
    "        yhat_answers = [q.answer_text for q in extractions]\n",
    "        yhat_answers = [text if text != None else \"\" for text in yhat_answers]\n",
    "        a_similarity = content_similarity(yhat_answers, y_answers)\n",
    "        print(f\"Answers similarity: Average={np.mean(a_similarity):.2f} Min={np.min(a_similarity):.2f} Max={np.max(a_similarity):.2f}\")\n",
    "\n",
    "    else:\n",
    "        print(\"No answers to be evaluated\")\n",
    "\n",
    "    # Section\n",
    "    if structure != None:\n",
    "        y_sections = [q['title'] for q in ground_truth['sections']]\n",
    "        yhat_sections = [q.section_title for q in structure.sections]\n",
    "        s_similarity = content_similarity(yhat_sections, y_sections)\n",
    "        print(f\"Section count accuracy: {count_accuracy(yhat_sections, y_sections):.2f}\")\n",
    "        print(f\"Section similarity: Average={np.mean(s_similarity):.2f} Min={np.min(s_similarity):.2f} Max={np.max(s_similarity):.2f}\")\n",
    "    else:\n",
    "        print(\"No document structure to be evaluated\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119462d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/dougsgrott-wsl/projects/local-doc-extractor/data/ground_truth/rfp_email.json\", \"r\") as f:\n",
    "    questions_ground_truth_esp = json.load(f)\n",
    "\n",
    "with open(\"/home/dougsgrott-wsl/projects/local-doc-extractor/data/ground_truth/rfp_market.json\", \"r\") as f:\n",
    "    questions_ground_truth_ip = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c441c199",
   "metadata": {},
   "source": [
    "## Document loading\n",
    "Ultimately, the PDF documents will be loaded using Azure Blob, and the text parsing can be done with either Azure Document Intelligence or some python open source package.\n",
    "\n",
    "Pros of Azure Document Intelligence:\n",
    "- Can be used for multiple file types (pdf, docx, etc)\n",
    "- Every extracted text is accompanied with a bounding box representing in its location on the document.\n",
    "  - This can be useful to filter out headers and footers, diminishing OCR noise.\n",
    "- The service tries to extract role of each element (paragraph, header, section, etc). This would be useful to programatically reconstruct the document structure without AI. The bad news is: it sucks.\n",
    "\n",
    "Cons of Azure Document Intelligence:\n",
    "- It's very, very costly.\n",
    "\n",
    "Here, I suggest and experiment with the possibility of using an open source python package meant only for PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a67a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different PDF loaders\n",
    "blob_url_ = \"https://stdocpipelinedev24o1.blob.core.windows.net/input-pdfs/RFP - Email Service Provider.pdf\"\n",
    "pdf_filepath_ = \"/home/dougsgrott-wsl/projects/local-doc-extractor/data/RFP - Email Service Provider.pdf\"\n",
    "\n",
    "text1 = analyze_pdf_with_docint(blob_url_)\n",
    "text2 = analyze_pdf_free(pdf_filepath_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb747c91",
   "metadata": {},
   "source": [
    "# Content Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da9e6ff",
   "metadata": {},
   "source": [
    "## RFP - Email Service Provider\n",
    "### (without answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://stdocpipelinedev24o1.blob.core.windows.net/input-pdfs/RFP - Email Service Provider.pdf\"\n",
    "doc = analyze_pdf_with_docint(url)\n",
    "parser = DocumentParser(margin_filter=MarginFilter(top=0.08, bottom=0.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = QuestionExtractorConfig(allowed_section_types=[SectionType.QUESTIONNAIRE])\n",
    "question_extractor = factory.create_question_extractor(\"simple_llm\") #, config\n",
    "questions_esp_simple = question_extractor.extract(doc['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_metrics(questions_esp_simple, questions_ground_truth_esp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc5a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = QuestionExtractorConfig(allowed_section_types=[SectionType.QUESTIONNAIRE])\n",
    "structure_extractor = factory.create_structure_extractor(\"structure_aware\")\n",
    "question_extractor = factory.create_question_extractor(\"context_aware\", config)\n",
    "question_extractor.set_structure_extractor(structure_extractor)\n",
    "\n",
    "questions_esp_aware = question_extractor.extract(doc['content'])\n",
    "structure_aware = question_extractor.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c0111",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_metrics(questions_esp_aware, questions_ground_truth_esp, structure_aware)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dffc677",
   "metadata": {},
   "source": [
    "### (with answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://stdocpipelinedev24o1.blob.core.windows.net/input-pdfs/RFP - Email Service Provider (with answers) v5.pdf\"\n",
    "doc = analyze_pdf_with_docint(url)\n",
    "parser = DocumentParser(margin_filter=MarginFilter(top=0.08, bottom=0.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95564f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = QAExtractorConfig(allowed_section_types=[SectionType.QUESTIONNAIRE])\n",
    "question_extractor = factory.create_qa_extractor(\"simple\") #, config\n",
    "questions_esp_simple = question_extractor.extract(doc['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746f5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_metrics(questions_esp_simple, questions_ground_truth_esp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad76d340",
   "metadata": {},
   "source": [
    "## RFP - Public Market, Template 1\n",
    " \n",
    "### (without answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19462f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://stdocpipelinedev24o1.blob.core.windows.net/input-pdfs/Public Market - Q template 1.pdf\"\n",
    "doc = analyze_pdf_with_docint(url)\n",
    "parser = DocumentParser(margin_filter=MarginFilter(top=0.08, bottom=0.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = QuestionExtractorConfig(allowed_section_types=[SectionType.QUESTIONNAIRE])\n",
    "question_extractor = factory.create_question_extractor(\"simple_llm\") #, config\n",
    "questions_esp_simple = question_extractor.extract(doc['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2313d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_metrics(questions_esp_simple, questions_ground_truth_ip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = QuestionExtractorConfig(allowed_section_types=[SectionType.QUESTIONNAIRE])\n",
    "structure_extractor = factory.create_structure_extractor(\"structure_aware\")\n",
    "question_extractor = factory.create_question_extractor(\"context_aware\", config)\n",
    "question_extractor.set_structure_extractor(structure_extractor)\n",
    "\n",
    "questions_esp_aware = question_extractor.extract(doc['content'])\n",
    "structure_aware = question_extractor.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66adc811",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_metrics(questions_esp_aware, questions_ground_truth_ip, structure_aware)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db09a57",
   "metadata": {},
   "source": [
    "### (with answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee22f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://stdocpipelinedev24o1.blob.core.windows.net/input-pdfs/Public Market - QA Template 1.pdf\"\n",
    "doc = analyze_pdf_with_docint(url)\n",
    "parser = DocumentParser(margin_filter=MarginFilter(top=0.08, bottom=0.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0103c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = QAExtractorConfig(allowed_section_types=[SectionType.QUESTIONNAIRE])\n",
    "question_extractor = factory.create_qa_extractor(\"simple\") #, config\n",
    "questions_esp_simple = question_extractor.extract(doc['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_metrics(questions_esp_simple, questions_ground_truth_ip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = QAExtractorConfig(allowed_section_types=[SectionType.QUESTIONNAIRE])\n",
    "structure_extractor = factory.create_structure_extractor(\"structure_aware\")\n",
    "question_extractor = factory.create_qa_extractor(\"context_aware\", config)\n",
    "question_extractor.set_structure_extractor(structure_extractor)\n",
    "\n",
    "questions_esp_aware = question_extractor.extract(doc['content'])\n",
    "structure_aware = question_extractor.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ce297",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_metrics(questions_esp_aware, questions_ground_truth_ip, structure_aware)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9a6773",
   "metadata": {},
   "source": [
    "## RFP - Public Market, Template 2\n",
    "\n",
    "### (without answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://stdocpipelinedev24o1.blob.core.windows.net/input-pdfs/Public Market - Q template 2.pdf\"\n",
    "doc = analyze_pdf_with_docint(url)\n",
    "\n",
    "\n",
    "config = QuestionExtractorConfig(allowed_section_types=[SectionType.QUESTIONNAIRE])\n",
    "\n",
    "structure_extractor = factory.create_structure_extractor(\"structure_aware\")\n",
    "\n",
    "question_extractor_ca = factory.create_question_extractor(\"context_aware\", config)\n",
    "questions_ca = question_extractor_ca.extract(doc['content'])\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "question_extractor_ag = factory.create_question_extractor(\"agentic\", config)\n",
    "questions_ag = question_extractor_ag.extract(doc['content'])\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "question_extractor_st_ca = factory.create_question_extractor(\"context_aware\", config)\n",
    "question_extractor_st_ca.set_structure_extractor(structure_extractor)\n",
    "questions_st_ca = question_extractor_st_ca.extract(doc['content'])\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "question_extractor_st_ag = factory.create_question_extractor(\"agentic\", config)\n",
    "question_extractor_st_ag.set_structure_extractor(structure_extractor)\n",
    "questions_st_ag = question_extractor_st_ag.extract(doc['content'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d36be97",
   "metadata": {},
   "source": [
    "# End-to-End Pipeline\n",
    "\n",
    "This combines document loading, OCR/text parsing, content extraction and persistence/database.\n",
    "\n",
    "Main idea is to implement dependency injection to reuse different components into different pipelines or Azure Functions, such that the code is reusable and modular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd4f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.core.processor import DocumentProcessor\n",
    "from shared.models.db import create_db_engine\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "url = \"https://stdocpipelinedev24o1.blob.core.windows.net/input-pdfs/RFP - Email Service Provider.pdf\"\n",
    "\n",
    "\n",
    "pdf_bytes = get_blob_content(url)\n",
    "engine = create_db_engine()\n",
    "processor = DocumentProcessor(\n",
    "    Session(engine),\n",
    "    parser=None,\n",
    "    analyzer=None,\n",
    "    extractor=None,\n",
    ")\n",
    "result = processor.process_document(pdf_bytes, \"file.pdf\", \"Client Name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7edd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-doc-extractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
